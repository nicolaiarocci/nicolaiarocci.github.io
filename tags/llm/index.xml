<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>llm on Nicola Iarocci</title>
    <link>https://nicolaiarocci.com/tags/llm/</link>
    <description>Recent content in llm on Nicola Iarocci</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 09 Dec 2023 07:05:25 +0100</lastBuildDate>
    <atom:link href="https://nicolaiarocci.com/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Quoting Andrej Karpathy</title>
      <link>https://nicolaiarocci.com/quoting-andrej-karpathy/</link>
      <pubDate>Sat, 09 Dec 2023 07:05:25 +0100</pubDate>
      <guid>https://nicolaiarocci.com/quoting-andrej-karpathy/</guid>
      <description>I always struggle a bit with I&amp;rsquo;m asked about the &amp;ldquo;hallucination problem&amp;rdquo; in LLMs. Because, in some sense, hallucination is all LLMs do. They are dream machines.
We direct their dreams with prompts. The prompts start the dream, and based on the LLM&amp;rsquo;s hazy recollection of its training documents, most of the time the result goes someplace useful.
It&amp;rsquo;s only when the dreams go into deemed factually incorrect territory that we label it a &amp;ldquo;hallucination&amp;rdquo;.</description>
    </item>
    <item>
      <title>Intro to Large Language Models (video)</title>
      <link>https://nicolaiarocci.com/intro-to-large-language-models-video/</link>
      <pubDate>Fri, 24 Nov 2023 07:05:25 +0100</pubDate>
      <guid>https://nicolaiarocci.com/intro-to-large-language-models-video/</guid>
      <description>Andrej Karpathy has a very well-done Intro to Large Language Models video on YouTube. As a founding member and research scientist at OpenAI and with a two-year hiatus working on Tesla Autopilot, Karpathy is an authority in the field. He is also good at explaining hard things.
As a Kahneman reader, I appreciated the Thinking Fast and Slow analogy proposed at about half-length in the video: &amp;ldquo;System 1&amp;rdquo; (fast automatic thinking, rapid decisions) is where we&amp;rsquo;re now; &amp;ldquo;System 2&amp;rdquo; (rational, slow thinking, complex decisions) is LLMs next goal.</description>
    </item>
    <item>
      <title>AI-curated minimalist news</title>
      <link>https://nicolaiarocci.com/ai-curated-minimalist-news/</link>
      <pubDate>Wed, 03 May 2023 07:05:25 +0100</pubDate>
      <guid>https://nicolaiarocci.com/ai-curated-minimalist-news/</guid>
      <description>Minimalist News is the first LLM project that excites me but in a nervous way. Quoting the About page:
We only publish significant news. To find them we use AI (ChatGPT-4) to read and analyze 1000 top news every day. For each article it estimates magnitude, scale, potential and credibility. Then we combine these estimates to get the final Significance score from 0 to 10. And now the best part: We&amp;rsquo;ll only send you the news scored 6.</description>
    </item>
  </channel>
</rss>
