<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Llm on Nicola Iarocci</title>
    <link>https://nicolaiarocci.com/tags/llm/</link>
    <description>Recent content in Llm on Nicola Iarocci</description>
    <generator>Hugo -- 0.143.1</generator>
    <language>en</language>
    <copyright>Produced / Written / Maintained by Nicola Iarocci since 2010</copyright>
    <lastBuildDate>Fri, 12 Dec 2025 08:22:18 +0100</lastBuildDate>
    <atom:link href="https://nicolaiarocci.com/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Programming isn&#39;t the job</title>
      <link>https://nicolaiarocci.com/programming-isnt-the-job/</link>
      <pubDate>Fri, 12 Dec 2025 08:22:18 +0100</pubDate>
      <guid>https://nicolaiarocci.com/programming-isnt-the-job/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;AI can replace most of programming, but programming isn’t the job. Programming is a task. It’s one of many things you do as part of your work. But if you’re a software engineer, your actual job is more than typing code into an editor. The mistake people make is conflating the task with the role.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;It’s like saying calculators replaced accountants. Calculators automated arithmetic, but arithmetic was never the job. The job was understanding financials, advising clients, making judgment calls, etc. The calculator just made accountants faster at the mechanical part. AI is doing something similar for us.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>AI can replace most of programming, but programming isn’t the job. Programming is a task. It’s one of many things you do as part of your work. But if you’re a software engineer, your actual job is more than typing code into an editor. The mistake people make is conflating the task with the role.</p></blockquote>
<blockquote>
<p>It’s like saying calculators replaced accountants. Calculators automated arithmetic, but arithmetic was never the job. The job was understanding financials, advising clients, making judgment calls, etc. The calculator just made accountants faster at the mechanical part. AI is doing something similar for us.</p></blockquote>
<p><a href="https://terriblesoftware.org/2025/12/11/ai-can-write-your-code-it-cant-do-your-job/">AI Can Write Your Code. It Can’t Do Your Job</a></p>
]]></content:encoded>
    </item>
    <item>
      <title>My session on MCP servers at .NET Conference Italia 2025</title>
      <link>https://nicolaiarocci.com/my-session-on-mcp-servers-at-dotnet-conference-italia-2025/</link>
      <pubDate>Wed, 26 Nov 2025 16:24:38 +0100</pubDate>
      <guid>https://nicolaiarocci.com/my-session-on-mcp-servers-at-dotnet-conference-italia-2025/</guid>
      <description>&lt;p&gt;I presented a session at the &lt;a href=&#34;https://www.aspitalia.com/eventi/97/.NET-Conference-Italia-2025-Milano.aspx&#34;&gt;.NET Conference Italia 2025&lt;/a&gt; in Milan a couple of weeks ago. The title was &amp;ldquo;Integrating our applications with LLMs and AI via MCP Servers&amp;rdquo;. It was well received; there were good questions throughout the talk and in the hall afterward. Surprisingly, live coding and demos went relatively smoothly.&lt;/p&gt;
&lt;p&gt;The fine guys at ASP Italia just published the &lt;a href=&#34;https://media.aspitalia.com/events/netconf25-LLM-dotNET-AI-MCP.media&#34;&gt;video&lt;/a&gt; in case someone is interested.&lt;/p&gt;
&lt;p&gt;Yeah, it is in Italian. I got a transcript from MacWhisper and then asked Claude to translate and clean it up. It did a pretty good job, so let me know if there&amp;rsquo;s any interest in an English transcript; I might post it here.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>I presented a session at the <a href="https://www.aspitalia.com/eventi/97/.NET-Conference-Italia-2025-Milano.aspx">.NET Conference Italia 2025</a> in Milan a couple of weeks ago. The title was &ldquo;Integrating our applications with LLMs and AI via MCP Servers&rdquo;. It was well received; there were good questions throughout the talk and in the hall afterward. Surprisingly, live coding and demos went relatively smoothly.</p>
<p>The fine guys at ASP Italia just published the <a href="https://media.aspitalia.com/events/netconf25-LLM-dotNET-AI-MCP.media">video</a> in case someone is interested.</p>
<p>Yeah, it is in Italian. I got a transcript from MacWhisper and then asked Claude to translate and clean it up. It did a pretty good job, so let me know if there&rsquo;s any interest in an English transcript; I might post it here.</p>
<p>Speaking of English, I&rsquo;ve started submitting to international events again, without any luck so far. The conference landscape has changed quite a bit, especially since the COVID break. I still get invited to local ones, while internationals have been elusive. I suspect my change in technology stack plays a role. It was relatively easy to speak abroad when I was into Python. With .NET, not so much. But again, I was into Python in the pre-COVID era, so it is hard to tell which factors are at play and what their weight is.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Beyond the machine</title>
      <link>https://nicolaiarocci.com/beyond-the-machine/</link>
      <pubDate>Tue, 21 Oct 2025 17:42:17 +0200</pubDate>
      <guid>https://nicolaiarocci.com/beyond-the-machine/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m just back from reading the transcript of &lt;a href=&#34;https://frankchimero.com/blog/2025/beyond-the-machine/&#34;&gt;Beyond the Machine&lt;/a&gt;, a thoughtful and insightful talk by Frank Chimero.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I’m trying to figure out how to use generative AI as a designer without feeling like shit. I am fascinated with what it can do, impressed and repulsed by what it makes, and distrustful of its owners. I am deeply ambivalent about it all. The believers demand devotion, the critics demand abstinence, and to see AI as just another technology is to be a heretic twice over.
Today, I’d like to try to open things up a bit.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>I&rsquo;m just back from reading the transcript of <a href="https://frankchimero.com/blog/2025/beyond-the-machine/">Beyond the Machine</a>, a thoughtful and insightful talk by Frank Chimero.</p>
<blockquote>
<p>I’m trying to figure out how to use generative AI as a designer without feeling like shit. I am fascinated with what it can do, impressed and repulsed by what it makes, and distrustful of its owners. I am deeply ambivalent about it all. The believers demand devotion, the critics demand abstinence, and to see AI as just another technology is to be a heretic twice over.
Today, I’d like to try to open things up a bit.</p></blockquote>
<p>I&rsquo;m surprised by how brilliantly Rick Rubin, Brian Eno, Hayao Miyazaki, and Miyazaki&rsquo;s <em>Spirited Away</em> are packed into this talk.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Invoicetronic, or what I&#39;ve been working on recently</title>
      <link>https://nicolaiarocci.com/invoicetronic-or-what-ive-been-working-on-recently/</link>
      <pubDate>Thu, 28 Aug 2025 10:07:05 +0200</pubDate>
      <guid>https://nicolaiarocci.com/invoicetronic-or-what-ive-been-working-on-recently/</guid>
      <description>&lt;p&gt;The most recent project I worked on is &lt;a href=&#34;https://invoicetronic.com/en/&#34;&gt;Invoicetronic&lt;/a&gt;, a modern API for complete management of the electronic invoicing cycle in Italy (FatturaPA/SDI).&lt;/p&gt;
&lt;p&gt;We had long used an internal API by our accounting software, which was also utilized by thousands of our end users. We decided to make our experience and expertise available to external developers, allowing them to integrate electronic invoicing into their applications quickly via a public API. Thus, the Invoicetronic project was born.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>The most recent project I worked on is <a href="https://invoicetronic.com/en/">Invoicetronic</a>, a modern API for complete management of the electronic invoicing cycle in Italy (FatturaPA/SDI).</p>
<p>We had long used an internal API by our accounting software, which was also utilized by thousands of our end users. We decided to make our experience and expertise available to external developers, allowing them to integrate electronic invoicing into their applications quickly via a public API. Thus, the Invoicetronic project was born.</p>
<p>We had made a similar choice in the past with the open-source release of <a href="https://github.com/FatturaElettronica/FatturaElettronica.NET">FatturaElettronica.NET</a>, also a library initially created for internal use. <a href="https://python-eve.org">Eve</a> and <a href="https://python-cerberus.org">Cerberus</a> for Python started as an internal projects too.</p>
<p>We didn&rsquo;t limit ourselves to just opening our API to the public. That alone would have been challenging (as any veteran well knows, opening a private product to a broader and more diverse audience is already a real challenge in itself). We seized the opportunity, years after its creation and with millions of invoices having passed through the system in the meantime, to refresh the design, improve performance, and add <a href="https://invoicetronic.com/en/features/">important features</a> that proved stimulating to implement.</p>
<p>I certainly wasn&rsquo;t lacking experience with REST APIs, but I still learned a lot, especially while working on the tools accessory to the actual API. An example is the client <a href="https://invoicetronic.com/en/docs/sdk/">SDKs</a>. We support all the most common programming languages: JavaScript/TypeScript, Python, PHP, Java, C#, Ruby, and Go. They&rsquo;re built using OpenAPI Generator, a tool I initially underestimated but which turned out to be excellent, thanks also to the remarkable ecosystem built by the community. Working on the SDKs also provided me with the opportunity to improve my Continuous Integration skills. Beyond the usual test-containerization-staging-deploy cycle, every API update is followed by an automatic release of all SDKs, each with deployment on both GitHub and the reference package manager for the language: PyPI, NuGet, npm, etc. Seemingly obvious tasks (such as inferring the new API version number from CI and then reusing it in the package version of individual SDKs) required considerable brainstorming.</p>
<p>The Invoicetronic project, which gave me the most satisfaction and taught me the most, is <a href="https://invoicetronic.com/en/docs/cli/#invoice"><code>invoice-cli</code></a>. This <a href="https://github.com/invoicetronic/invoice-cli">open source</a> command-line tool enables sending and receiving electronic invoices from the terminal, and is available for Linux, Mac, and Windows. You don&rsquo;t need to be a developer or study the API in depth to use it, and, not secondarily, it can be conveniently inserted into a script. A trivial usage example would be:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span># send a single invoice.
</span></span><span style="display:flex;"><span>$ invoice send file1.xml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># send multiple invoices, then delete the local copies.
</span></span><span style="display:flex;"><span>$ invoice send *.xml --delete
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># individually send multiple files.
</span></span><span style="display:flex;"><span>$ invoice send file1.xml file2.xml file3.xml
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span># receive all unread invoices.
</span></span><span style="display:flex;"><span>$ invoice receive --unread
</span></span></code></pre></div><p>From my point of view, though, the interesting thing about <code>invoice</code> is that it&rsquo;s written in Go, a language I hadn&rsquo;t yet had the chance to use professionally. A veteran would likely find fault with the implementation details and the chosen approach, but I hope they&rsquo;ll be merciful, considering I&rsquo;m a beginner in this space. We could have used C#, which is now our reference language. Still, in the case of the command-line, Go seemed like a better choice, first of all, for the exceptional support in creating native multi-platform binaries, then for performance both cold and hot, and for deployment simplicity. If I had to make another command-line tool, I would return to Go rather than orient myself toward languages I know better and with which I&rsquo;m more comfortable, like Python and C# (speaking of C#, the recent improvements in AOT and cross-platform support are remarkable - we&rsquo;re on the right track, come on guys!)</p>
<p>A second stimulating project was the <a href="https://invoicetronic.com/en/features/#llm-and-ai-integration">Invoicetronic MCP Server.</a> We were interested in having developers interact with the Invoicetronic API via LLM, and an MCP server serves precisely that purpose. Fortunately, C# has an excellent official library (still in preview but sufficiently mature) that simplifies the work, and implementing and deploying a first experimental version was relatively simple. There is enormous potential in this area, and I want to stay on top of it: objective achieved (I also gave a <a href="https://nicolaiarocci.com/im-speaking-at-devmarche-summer-ai-afternoon/">couple</a> of <a href="https://nicolaiarocci.com/mcp-or-connecting-our-apps-to-llms/">presentations</a> on the topic).</p>
<p>We released Invoicetronic for our own use, but I hope other developers will adopt it. Throughout many years of activity, our primary client has consistently been the end-user, the company that utilizes our accounting applications. In recent years, we also engaged with developers, but only in the context of our open-source projects. I&rsquo;d love to serve them professionally as well.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Old timers who built the early web are coding with AI like it&#39;s 1995</title>
      <link>https://nicolaiarocci.com/old-timers-who-built-the-early-web-are-coding-with-ai-like-its-1995/</link>
      <pubDate>Fri, 01 Aug 2025 08:19:05 +0200</pubDate>
      <guid>https://nicolaiarocci.com/old-timers-who-built-the-early-web-are-coding-with-ai-like-its-1995/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;The old timers who built the early web are coding with AI like it&amp;rsquo;s 1995. Think about it: They gave blockchain the sniff test and walked away. Ignored crypto (and yeah, we&amp;rsquo;re not rich now). NFTs got a collective eye roll. But AI? Different story. The same folks who hand-coded HTML while listening to dial-up modems sing are now vibe-coding with the kids. Building things. Breaking things. Giddy about it.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>The old timers who built the early web are coding with AI like it&rsquo;s 1995. Think about it: They gave blockchain the sniff test and walked away. Ignored crypto (and yeah, we&rsquo;re not rich now). NFTs got a collective eye roll. But AI? Different story. The same folks who hand-coded HTML while listening to dial-up modems sing are now vibe-coding with the kids. Building things. Breaking things. Giddy about it.</p></blockquote>
<blockquote>
<p>We Gen X&rsquo;ers have seen enough gold rushes to know the real thing. This one&rsquo;s got all the usual crap—bad actors, inflated claims, VCs throwing money at anything with &ldquo;AI&rdquo; in the pitch deck. Gross behavior all around. Normal for a paradigm shift, but still gross.</p></blockquote>
<blockquote>
<p>The people who helped wire up the internet recognize what&rsquo;s happening. When the folks who&rsquo;ve been through every tech cycle since gopher start acting like excited newbies again, that tells you something.</p></blockquote>
<p>&ndash; <a href="https://www.linkedin.com/posts/christinawodtke_the-old-timers-who-built-the-early-web-are-activity-7356335847614402560-8nKx/">Christina Wodtke</a> (<a href="https://simonwillison.net/2025/Jul/31/christina-wodtke/#atom-everything">via</a>)</p>
]]></content:encoded>
    </item>
    <item>
      <title>What doesn&#39;t change</title>
      <link>https://nicolaiarocci.com/what-doesnt-change/</link>
      <pubDate>Mon, 14 Jul 2025 16:28:26 +0200</pubDate>
      <guid>https://nicolaiarocci.com/what-doesnt-change/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Everyone’s either panicking that AI will replace them or assuming they don’t need to learn anything anymore. Both miss the point entirely. AI amplifies what you already know. If you understand distributed systems, you’ll use AI to build better ones. If you don’t, you’ll use AI to create distributed disasters.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The difference? When that AI-generated code breaks in production — and it will — you need to know why. When it doesn’t scale — and it won’t — you need to understand the bottlenecks. When it creates race conditions, memory leaks, or architectural nightmares, GitHub Copilot won’t save you. &lt;strong&gt;Your fundamentals will&lt;/strong&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>Everyone’s either panicking that AI will replace them or assuming they don’t need to learn anything anymore. Both miss the point entirely. AI amplifies what you already know. If you understand distributed systems, you’ll use AI to build better ones. If you don’t, you’ll use AI to create distributed disasters.</p></blockquote>
<blockquote>
<p>The difference? When that AI-generated code breaks in production — and it will — you need to know why. When it doesn’t scale — and it won’t — you need to understand the bottlenecks. When it creates race conditions, memory leaks, or architectural nightmares, GitHub Copilot won’t save you. <strong>Your fundamentals will</strong>.</p></blockquote>
<p><a href="https://terriblesoftware.org/2025/07/14/what-doesnt-change/">What Doesn&rsquo;t Change</a></p>
]]></content:encoded>
    </item>
    <item>
      <title>I&#39;m speaking at DevMarche Summer AI Afternoon</title>
      <link>https://nicolaiarocci.com/im-speaking-at-devmarche-summer-ai-afternoon/</link>
      <pubDate>Tue, 08 Jul 2025 10:59:39 +0200</pubDate>
      <guid>https://nicolaiarocci.com/im-speaking-at-devmarche-summer-ai-afternoon/</guid>
      <description>&lt;p&gt;On Thursday, I will be conducting an MCP Server session at the &lt;a href=&#34;https://www.eventbrite.it/e/summer-ai-afternoon-tickets-1428458029419&#34;&gt;Summer AI Afternoon&lt;/a&gt; event organized by &lt;a href=&#34;https://dev.marche.it&#34;&gt;DevMarche&lt;/a&gt; in collaboration with &lt;a href=&#34;https://devromagna.org&#34;&gt;DevRomagna&lt;/a&gt;, the neighbouring development communities. There are more than 50 people signed up already, and I&amp;rsquo;m so looking forward to meeting old and new friends down South.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>On Thursday, I will be conducting an MCP Server session at the <a href="https://www.eventbrite.it/e/summer-ai-afternoon-tickets-1428458029419">Summer AI Afternoon</a> event organized by <a href="https://dev.marche.it">DevMarche</a> in collaboration with <a href="https://devromagna.org">DevRomagna</a>, the neighbouring development communities. There are more than 50 people signed up already, and I&rsquo;m so looking forward to meeting old and new friends down South.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Cloudflare to introduce pay-per-crawl for AI bots</title>
      <link>https://nicolaiarocci.com/cloudflare-to-introduce-pay-per-crawl-for-ai-bots/</link>
      <pubDate>Wed, 02 Jul 2025 09:57:57 +0200</pubDate>
      <guid>https://nicolaiarocci.com/cloudflare-to-introduce-pay-per-crawl-for-ai-bots/</guid>
      <description>&lt;p&gt;The biggest news in tech this week (which isn&amp;rsquo;t over yet) is, without a doubt, that &lt;a href=&#34;https://blog.cloudflare.com/introducing-pay-per-crawl/&#34;&gt;Cloudflare is about to introduce a pay-per-crawl model for AI bots&lt;/a&gt;—huge in many ways, as let&amp;rsquo;s not forget that approximately 20% of internet traffic is routed through Cloudflare.&lt;/p&gt;
&lt;p&gt;I have many thoughts right now, and it will take some time for them to settle. A good analysis and explanation of why this move is needed and is a good first step can be found in yesterday&amp;rsquo;s article by Dries Buytaert&amp;rsquo;s, &lt;a href=&#34;https://dri.es/the-webs-broken-deal-with-ai-companies&#34;&gt;The Web&amp;rsquo;s Broken Deal with AI Companies&lt;/a&gt;, which I recommend everyone read.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>The biggest news in tech this week (which isn&rsquo;t over yet) is, without a doubt, that <a href="https://blog.cloudflare.com/introducing-pay-per-crawl/">Cloudflare is about to introduce a pay-per-crawl model for AI bots</a>—huge in many ways, as let&rsquo;s not forget that approximately 20% of internet traffic is routed through Cloudflare.</p>
<p>I have many thoughts right now, and it will take some time for them to settle. A good analysis and explanation of why this move is needed and is a good first step can be found in yesterday&rsquo;s article by Dries Buytaert&rsquo;s, <a href="https://dri.es/the-webs-broken-deal-with-ai-companies">The Web&rsquo;s Broken Deal with AI Companies</a>, which I recommend everyone read.</p>
<blockquote>
<p>For 25 years, we built the Open Web on an implicit agreement: search engines could index our content because they sent users back to our websites. That model helped sustain blogs, news sites, and even open source projects. AI companies broke that model. They train on our work and answer questions directly in their own interfaces, cutting creators out entirely. Anthropic&rsquo;s crawler reportedly makes 70,000 website requests for every single visitor it sends back. That is extraction, not exchange.</p></blockquote>
<p>The ongoing discussion on <a href="https://news.ycombinator.com/item?id=44432385">Hacker News</a> is also worth reading</p>
<p>Side note, I am fascinated by the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status/402">technical details</a> surrounding the 402 Payment Required response (and <a href="https://blog.cloudflare.com/introducing-pay-per-crawl/#publisher-controls-and-pricing">Cloudflare&rsquo;s implementation</a>), which was designed explicitly for micro-payment handling but never gained traction, until now.</p>
]]></content:encoded>
    </item>
    <item>
      <title>AI coding is less fun</title>
      <link>https://nicolaiarocci.com/ai-coding-is-less-fun/</link>
      <pubDate>Thu, 19 Jun 2025 10:30:51 +0200</pubDate>
      <guid>https://nicolaiarocci.com/ai-coding-is-less-fun/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve been doing &amp;ldquo;agentic coding&amp;rdquo; for some time, and well, it&amp;rsquo;s weird. On stable, mature technology (in my case, the C#/.NET stack), it is beneficial, as it significantly boosts productivity.&lt;/p&gt;
&lt;p&gt;But, there&amp;rsquo;s a bit, and that&amp;rsquo;s that I&amp;rsquo;m not programming anymore, or very little now, and I love coding. I love entering &amp;ldquo;the zone&amp;rdquo; and solving complex problems, one at a time. It&amp;rsquo;s always been my superpower. Will I still have fun in the future now that I can delegate most tasks to Claude Code?&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>I&rsquo;ve been doing &ldquo;agentic coding&rdquo; for some time, and well, it&rsquo;s weird. On stable, mature technology (in my case, the C#/.NET stack), it is beneficial, as it significantly boosts productivity.</p>
<p>But, there&rsquo;s a bit, and that&rsquo;s that I&rsquo;m not programming anymore, or very little now, and I love coding. I love entering &ldquo;the zone&rdquo; and solving complex problems, one at a time. It&rsquo;s always been my superpower. Will I still have fun in the future now that I can delegate most tasks to Claude Code?</p>
<p>In his <a href="https://terriblesoftware.org/2025/04/23/the-hidden-cost-of-ai-coding/">The Hidden Cost of AI Coding</a>, Matheus Lima expresses the same concern:</p>
<blockquote>
<p>Instead of that deep immersion where I&rsquo;d craft each function, I&rsquo;m now more like a <em>curator</em>? I describe what I want, evaluate what the AI gives me, tweak the prompts, and iterate. It&rsquo;s efficient, yes. Revolutionary, even. But something essential feels missing — that state of flow where time vanishes and you&rsquo;re completely absorbed in creation. If this becomes the dominant workflow across teams, do we risk an industry full of highly productive yet strangely detached developers?</p></blockquote>
<p>I&rsquo;m afraid there&rsquo;s no going back; agentic coding is so helpful that it&rsquo;s tough to let go, especially in tiny teams like mine. Matheus suggests we preserve some space in our work where the flow can still happen, and that&rsquo;s probably what I&rsquo;m going to do: on some projects, maybe the open-source ones I maintain, resist the temptation of a <code>claude /init</code> and keep going like the good old times. One can at least try.</p>
]]></content:encoded>
    </item>
    <item>
      <title>MCP Remote</title>
      <link>https://nicolaiarocci.com/mcp-remote/</link>
      <pubDate>Wed, 18 Jun 2025 10:36:39 +0200</pubDate>
      <guid>https://nicolaiarocci.com/mcp-remote/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve been implementing a remote &lt;a href=&#34;https://modelcontextprotocol.io&#34;&gt;MCP Server&lt;/a&gt;. It comes with a hybrid authentication system that supports the OAuth2 flow and, as a fallback, a custom header for those simple clients that cannot handle OAuth. One such client is Claude Desktop, which, at this time, is even worse; it only supports STDIO (local) servers, let alone OAuth2.&lt;/p&gt;
&lt;p&gt;Today I learned about a nice NPM package called &lt;a href=&#34;https://www.npmjs.com/package/mcp-remote&#34;&gt;MCP Remote&lt;/a&gt;, which bridges the gap by allowing MCP clients that only support local servers to connect to remote MCP Servers, even with authentication support. Thanks to this tool, Claude Desktop is now talking to my remote server&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>I&rsquo;ve been implementing a remote <a href="https://modelcontextprotocol.io">MCP Server</a>. It comes with a hybrid authentication system that supports the OAuth2 flow and, as a fallback, a custom header for those simple clients that cannot handle OAuth. One such client is Claude Desktop, which, at this time, is even worse; it only supports STDIO (local) servers, let alone OAuth2.</p>
<p>Today I learned about a nice NPM package called <a href="https://www.npmjs.com/package/mcp-remote">MCP Remote</a>, which bridges the gap by allowing MCP clients that only support local servers to connect to remote MCP Servers, even with authentication support. Thanks to this tool, Claude Desktop is now talking to my remote server<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>The only problem is that the OAuth2 handshake is not initiated at Claude startup or the first 401 response, as I expected, so I had to fall back to my secondary authentication method, the custom header.</p>
<p>I could, of course, retrieve my OAuth2 token out of band and then pass it to MCP Remote, but that&rsquo;s cumbersome and boring. For now, I&rsquo;m satisfied with the custom header approach. It&rsquo;s only a matter of time before Claude Desktop matures enough to fully support Remote MCP servers. Right?</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>For testing purposes, I primarily resort to <a href="https://modelcontextprotocol.io/docs/tools/inspector">MCP Inspector</a>, the reference tool; however, it&rsquo;s also nice to experiment with a reference large language model (LLM), mainly to assess the potential once the server is connected to it.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>The empire strikes back</title>
      <link>https://nicolaiarocci.com/the-empire-strikes-back/</link>
      <pubDate>Sat, 14 Jun 2025 10:57:48 +0200</pubDate>
      <guid>https://nicolaiarocci.com/the-empire-strikes-back/</guid>
      <description>&lt;p&gt;Quoting straight from &lt;a href=&#34;https://notes.jim-nielsen.com/#2025-06-13T0927&#34;&gt;Jim Nielsen&amp;rsquo;s note&lt;/a&gt; on LLM training on copyrighted data:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As a broke teenager, the web was this strange wonderland where you could access all kinds of copyrighted material using tools developed by fringe individuals/communities: Napster, Kazaa, Torrents, Usenet, etc. These tools (at least in the beginning) weren’t really made for profit, just to subvert the gatekeepers (and yeah, steal their profits).&lt;/p&gt;
&lt;p&gt;Now — in a strange twist of irony — things seem to have flipped:&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Quoting straight from <a href="https://notes.jim-nielsen.com/#2025-06-13T0927">Jim Nielsen&rsquo;s note</a> on LLM training on copyrighted data:</p>
<blockquote>
<p>As a broke teenager, the web was this strange wonderland where you could access all kinds of copyrighted material using tools developed by fringe individuals/communities: Napster, Kazaa, Torrents, Usenet, etc. These tools (at least in the beginning) weren’t really made for profit, just to subvert the gatekeepers (and yeah, steal their profits).</p>
<p>Now — in a strange twist of irony — things seem to have flipped:</p>
<ul>
<li>1999: Individuals use digital tools to steal intellectual property from corporations.</li>
<li>2025: Corporations use digital tools to steal intellectual property from individuals.</li>
</ul>
<p>The empire strikes back.</p></blockquote>
]]></content:encoded>
    </item>
    <item>
      <title>Agentic coding recommendations</title>
      <link>https://nicolaiarocci.com/agentic-coding-recommendations/</link>
      <pubDate>Thu, 12 Jun 2025 18:15:42 +0200</pubDate>
      <guid>https://nicolaiarocci.com/agentic-coding-recommendations/</guid>
      <description>&lt;p&gt;Armin Ronacher is on a roll. He just published his &lt;a href=&#34;https://lucumr.pocoo.org/2025/6/12/agentic-coding/&#34;&gt;Agentic Coding Reccomendations&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On the topic of Agenting Coding he recently published:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://lucumr.pocoo.org/2025/6/4/changes/&#34;&gt;AI Changes Everything&lt;/a&gt; (you should read it)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lucumr.pocoo.org/2025/6/10/genai-criticism/&#34;&gt;GenAI Criticism and Moral Quandaries&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both already &lt;a href=&#34;http://localhost:1313/ai-changes-everything/&#34;&gt;reported&lt;/a&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Armin Ronacher is on a roll. He just published his <a href="https://lucumr.pocoo.org/2025/6/12/agentic-coding/">Agentic Coding Reccomendations</a>.</p>
<p>On the topic of Agenting Coding he recently published:</p>
<ul>
<li><a href="https://lucumr.pocoo.org/2025/6/4/changes/">AI Changes Everything</a> (you should read it)</li>
<li><a href="https://lucumr.pocoo.org/2025/6/10/genai-criticism/">GenAI Criticism and Moral Quandaries</a></li>
</ul>
<p>Both already <a href="http://localhost:1313/ai-changes-everything/">reported</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>MCP or connecting our apps to LLMs</title>
      <link>https://nicolaiarocci.com/mcp-or-connecting-our-apps-to-llms/</link>
      <pubDate>Thu, 12 Jun 2025 09:23:46 +0200</pubDate>
      <guid>https://nicolaiarocci.com/mcp-or-connecting-our-apps-to-llms/</guid>
      <description>&lt;p&gt;Last night, I presented a session titled &lt;a href=&#34;https://www.meetup.com/devromagna/events/308179204/&#34;&gt;MCP or Connecting our Apps to LLMs&lt;/a&gt; at DevRomagna, our local developer&amp;rsquo;s community, and I think it went well.&lt;/p&gt;
&lt;p&gt;I had intended to record the audio with the idea of transcribing it with MacWhisper and then publishing it here on my site, but I forgot to do so, which is a pity.&lt;/p&gt;
&lt;p&gt;The session lasted almost two hours (I had thought it would take less time), during which I deviated somewhat from the script, using slides as a guide that were essentially an adaptation of the notes I had taken during my experiments. I showed the code for the MCP servers I created (stdio and streamable HTTP transports), demonstrated the various ways to link them with LLMs (Claude Desktop, Claude Code, and VS Code), and then shared my thoughts on the entire matter.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Last night, I presented a session titled <a href="https://www.meetup.com/devromagna/events/308179204/">MCP or Connecting our Apps to LLMs</a> at DevRomagna, our local developer&rsquo;s community, and I think it went well.</p>
<p>I had intended to record the audio with the idea of transcribing it with MacWhisper and then publishing it here on my site, but I forgot to do so, which is a pity.</p>
<p>The session lasted almost two hours (I had thought it would take less time), during which I deviated somewhat from the script, using slides as a guide that were essentially an adaptation of the notes I had taken during my experiments. I showed the code for the MCP servers I created (stdio and streamable HTTP transports), demonstrated the various ways to link them with LLMs (Claude Desktop, Claude Code, and VS Code), and then shared my thoughts on the entire matter.</p>
<p>I received quite a bit of feedback, both in the room and afterward, when we moved to a pub where we stayed quite late by my standards, discussing AI, LLMs, and their impact on our daily work, which we can certainly define as significant, if not massive. Everyone uses LLMs&rsquo; UIs at their job to some extent, but very few are currently into agentic coding (the idea of a future session on that topic is tempting).</p>
<p>One remarkable tool that surfaced during the pub chat is <a href="https://github.com/Cinnamon/kotaemon">Kotaemon</a>, <em>&ldquo;an open-source RAG-based tool for chatting with your documents.&rdquo;</em>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Quoting Sam Altman</title>
      <link>https://nicolaiarocci.com/quoting-sam-altman/</link>
      <pubDate>Wed, 11 Jun 2025 14:20:55 +0200</pubDate>
      <guid>https://nicolaiarocci.com/quoting-sam-altman/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;In the 2030s, intelligence and energy—ideas, and the ability to make ideas happen—are going to become wildly abundant. These two have been the fundamental limiters on human progress for a long time; with abundant intelligence and energy (and good governance), we can theoretically have anything else.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&amp;ndash; &lt;a href=&#34;https://blog.samaltman.com/the-gentle-singularity&#34;&gt;Sam Altman&lt;/a&gt;&lt;/p&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>In the 2030s, intelligence and energy—ideas, and the ability to make ideas happen—are going to become wildly abundant. These two have been the fundamental limiters on human progress for a long time; with abundant intelligence and energy (and good governance), we can theoretically have anything else.</p></blockquote>
<p>&ndash; <a href="https://blog.samaltman.com/the-gentle-singularity">Sam Altman</a></p>
]]></content:encoded>
    </item>
    <item>
      <title>What happens when people don&#39;t understand how AI works</title>
      <link>https://nicolaiarocci.com/what-happens-when-people-dont-understand-how-ai-works/</link>
      <pubDate>Mon, 09 Jun 2025 14:32:13 +0200</pubDate>
      <guid>https://nicolaiarocci.com/what-happens-when-people-dont-understand-how-ai-works/</guid>
      <description>Despite what tech CEOs might say, large language models are not smart in any recognizably human sense of the word.</description>
      <content:encoded><![CDATA[<p>This week&rsquo;s obligatory yet solid warning about the misunderstanding of LLMs comes from Tyler Austin Harper&rsquo;s <a href="https://archive.is/NJ9K0#selection-615.3-617.19">What Happens When People Don&rsquo;t Understand How AI Works</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Claude Code first impressions</title>
      <link>https://nicolaiarocci.com/claude-code-first-impressions/</link>
      <pubDate>Thu, 05 Jun 2025 18:02:55 +0200</pubDate>
      <guid>https://nicolaiarocci.com/claude-code-first-impressions/</guid>
      <description>&lt;p&gt;Since yesterday, Claude Code has been included in the Pro subscription we&amp;rsquo;re signed up for. I&amp;rsquo;d been wanting to try it for a while, and now nothing was stopping me. Only yesterday (a curious coincidence), I read &lt;a href=&#34;https://nicolaiarocci.com/ai-changes-everything/&#34;&gt;AI Changes Everything&lt;/a&gt; by Armin Ronacher, which gave me a glimpse of the potential and made my hands itch to try it.&lt;/p&gt;
&lt;p&gt;The initialization of Claude on the repository surprised me; the analysis (reported in CLAUDE.md) is thorough and reveals a good understanding of the project, including both the code and the general functioning, strategies, techniques, technologies and libraries employed.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Since yesterday, Claude Code has been included in the Pro subscription we&rsquo;re signed up for. I&rsquo;d been wanting to try it for a while, and now nothing was stopping me. Only yesterday (a curious coincidence), I read <a href="/ai-changes-everything/">AI Changes Everything</a> by Armin Ronacher, which gave me a glimpse of the potential and made my hands itch to try it.</p>
<p>The initialization of Claude on the repository surprised me; the analysis (reported in CLAUDE.md) is thorough and reveals a good understanding of the project, including both the code and the general functioning, strategies, techniques, technologies and libraries employed.</p>
<p>I asked Claude to generate a test suite from scratch, and it did so rather effortlessly (it went back and forth a few times, and it is fascinating following its reasoning and attempts from a distance). Claude added the tests to the existing project, a big no-no for me. I asked it to go back and create a dedicated test project, and it complied, adding the new project to the solution. It took several iterations to achieve a good result. We now have 134 tests that cover 98% of the project&rsquo;s business logic. Upon request, Claude also added code coverage by installing the missing tools.</p>
<p>Once satisfied with the test suite and having committed and pushed (via Claude) the work done, I asked Claude to set up a GitHub Action to run the tests on every push, then to update the existing workflows (container build; deployment to test or production; etc.) so they all run tests first.</p>
<p>In half a day of work, during which I mostly did other things, such as helping a colleague while Claude was chugging away, I achieved what would have taken me a week or even just a few days.</p>
<p>I have very little to complain about in terms of code quality, and where I wasn&rsquo;t satisfied, I informed Claude and the unsatisfying code was quickly and pleasantly refactored. However, some refactoring is better done with Rider because it&rsquo;s faster, doesn&rsquo;t miss anything (like Claude tends to do if there are multiple similar refactorings to be done and they are scattered across various files) and doesn&rsquo;t waste tokens that count toward usage limits (with the Pro subscription, we have access to a lighter tier of Claude Code. You want the Max subscription for unlimited - or higher anyway- ceiling).</p>
<p>One valuable feature is memory. You can have Claude memorize directives. This memory can be local to the repo or global. I instructed Claude to prefer collection expressions and utilize C#&rsquo;s new targeted-type initialization feature, among other things, which were duly noted. I then asked Claude to refactor in light of the new directives, and it did. New code is now produced according to my preferences, and it will be on all my projects.</p>
<p>A thorough code review is always necessary, of course, but wouldn&rsquo;t you do that for any code coming into your project?</p>
<p>Color me impressed so far. Copying and pasting from LLM&rsquo;s web UIs is already a thing of the past. The present is all about agents, and they&rsquo;re just getting started.</p>
]]></content:encoded>
    </item>
    <item>
      <title>AI changes everything</title>
      <link>https://nicolaiarocci.com/ai-changes-everything/</link>
      <pubDate>Wed, 04 Jun 2025 15:21:21 +0200</pubDate>
      <guid>https://nicolaiarocci.com/ai-changes-everything/</guid>
      <description>&lt;p&gt;Today&amp;rsquo;s Armin Ronacher&amp;rsquo;s &lt;a href=&#34;https://lucumr.pocoo.org/2025/6/4/changes/&#34;&gt;AI Changes Everything&lt;/a&gt; strongly resonates with me&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. I may not be using Claude Code as a daily driver as he now does, but I&amp;rsquo;ve slowly and steadily introduced large language models (LLMs) into my routine, and I&amp;rsquo;m reaping the benefits.&lt;/p&gt;
&lt;p&gt;It wasn&amp;rsquo;t the purpose of his article, but I wish Armin had gone into the details of how, why, and when he delegates tasks to Claude Code.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt; Armin later a &lt;a href=&#34;https://lucumr.pocoo.org/2025/6/10/genai-criticism/&#34;&gt;follow-up&lt;/a&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Today&rsquo;s Armin Ronacher&rsquo;s <a href="https://lucumr.pocoo.org/2025/6/4/changes/">AI Changes Everything</a> strongly resonates with me<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I may not be using Claude Code as a daily driver as he now does, but I&rsquo;ve slowly and steadily introduced large language models (LLMs) into my routine, and I&rsquo;m reaping the benefits.</p>
<p>It wasn&rsquo;t the purpose of his article, but I wish Armin had gone into the details of how, why, and when he delegates tasks to Claude Code.</p>
<p><em>Update:</em> Armin later a <a href="https://lucumr.pocoo.org/2025/6/10/genai-criticism/">follow-up</a>.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://fly.io/blog/youre-all-nuts/">My AI Skeptic Friends All Nuts</a>, linked in Armin&rsquo;s piece, is also worth reading.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>Run your own AI</title>
      <link>https://nicolaiarocci.com/run-your-own-ai/</link>
      <pubDate>Wed, 04 Jun 2025 08:43:28 +0200</pubDate>
      <guid>https://nicolaiarocci.com/run-your-own-ai/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://anthonylewis.com/2025/06/01/run-your-own-ai/&#34;&gt;Run Your Own AI&lt;/a&gt;&lt;/strong&gt; by Anthony Lewis is a concise tutorial on how to run large language models on your laptop from the command line via &lt;a href=&#34;https://simonwillison.net/2025/Feb/15/llm-mlx/&#34;&gt;llm-mlx&lt;/a&gt;. It focuses on Macs M-series, but it&amp;rsquo;s also suitable for other hardware. Saving it here for a friend.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p><strong><a href="https://anthonylewis.com/2025/06/01/run-your-own-ai/">Run Your Own AI</a></strong> by Anthony Lewis is a concise tutorial on how to run large language models on your laptop from the command line via <a href="https://simonwillison.net/2025/Feb/15/llm-mlx/">llm-mlx</a>. It focuses on Macs M-series, but it&rsquo;s also suitable for other hardware. Saving it here for a friend.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Why do earthworms appear on wet roads?</title>
      <link>https://nicolaiarocci.com/why-do-earthworms-appear-on-wet-roads/</link>
      <pubDate>Fri, 14 Mar 2025 08:52:37 +0100</pubDate>
      <guid>https://nicolaiarocci.com/why-do-earthworms-appear-on-wet-roads/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s raining a lot these days, and during my early morning walk, I see many earthworms popping out of the ground and filling the sidewalks and the streets. I observed this behaviour many times in similarly wet conditions. So I asked Claude: &lt;em&gt;Why do earthworms appear on wet roads?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;When it rains heavily, streets fill with earthworms for several reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Earthworms breathe through their skin, which must remain moist. During heavy rainfall, their underground tunnels flood, forcing them to surface to avoid drowning.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>It&rsquo;s raining a lot these days, and during my early morning walk, I see many earthworms popping out of the ground and filling the sidewalks and the streets. I observed this behaviour many times in similarly wet conditions. So I asked Claude: <em>Why do earthworms appear on wet roads?</em></p>
<p>When it rains heavily, streets fill with earthworms for several reasons:</p>
<ol>
<li>
<p>Earthworms breathe through their skin, which must remain moist. During heavy rainfall, their underground tunnels flood, forcing them to surface to avoid drowning.</p>
</li>
<li>
<p>The vibrations of raindrops on the soil can be mistaken by earthworms for those produced by predators like moles, causing them to flee to the surface.</p>
</li>
<li>
<p>Rainy periods are ideal for earthworms to move and find new habitats or mates, as they can travel on the moist surface without risking dehydration.</p>
</li>
<li>
<p>On paved surfaces like roads and sidewalks, water tends to accumulate more than in soil, creating conditions that attract earthworms.</p>
</li>
</ol>
<p>Unfortunately, once earthworms reach the asphalt, they often become trapped and unable to return to the soil, becoming easy prey or risking dehydration when the sun returns.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Reading books and commenting on them with ChatGPT</title>
      <link>https://nicolaiarocci.com/reading-books-and-commenting-on-them-with-chatgpt/</link>
      <pubDate>Tue, 26 Nov 2024 19:20:01 +0100</pubDate>
      <guid>https://nicolaiarocci.com/reading-books-and-commenting-on-them-with-chatgpt/</guid>
      <description>&lt;p&gt;I just finished reading Paul Auster&amp;rsquo;s The New York Trilogy&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. On this occasion, I discovered a new use for ChatGPT and LLMs. ChatGPT and I chatted about the themes, especially the correlations and connections between the three short novels that comprise the volume. It was an alienating and revealing experience. For the first time, I am reasoning about a book with a machine, not a person. Because it knows everything about the text and draws on the shared global knowledge, it can give more satisfaction than most people do (also, it&amp;rsquo;s not easy to find someone around with whom I can talk about all the books I read!) Yes, it is wordy and repetitive, but it can stimulate and enrich my analysis&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>I just finished reading Paul Auster&rsquo;s The New York Trilogy<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. On this occasion, I discovered a new use for ChatGPT and LLMs. ChatGPT and I chatted about the themes, especially the correlations and connections between the three short novels that comprise the volume. It was an alienating and revealing experience. For the first time, I am reasoning about a book with a machine, not a person. Because it knows everything about the text and draws on the shared global knowledge, it can give more satisfaction than most people do (also, it&rsquo;s not easy to find someone around with whom I can talk about all the books I read!) Yes, it is wordy and repetitive, but it can stimulate and enrich my analysis<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>I&rsquo;ve been using LLMs (ChatGPT and Claude) more and more lately, especially for work. The more I use them, the more I understand how to leverage their capabilities. I would have never thought about sharing my reading experiences with ChatGPT before. <a href="https://www.oneusefulthing.org/p/getting-started-with-ai-good-enough">Ethan Mollick</a> has it right; we should all put at least 10 hours into LLMs before judging them.</p>
<blockquote>
<p>Your goal is simple: spend 10 hours using AI on tasks that actually matter to you. After that, you&rsquo;ll have a natural sense of how AI fits into your work and life. You&rsquo;ll develop an intuition for effective prompting, and you&rsquo;ll better understand AI&rsquo;s potential. Don&rsquo;t aim for perfection - just start somewhere and learn as you go.</p></blockquote>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I&rsquo;ve not been posting my usual short book reviews in 2024. I&rsquo;m reading a lot, though, and updating a &ldquo;Books I read in 2024&rdquo; article as I go on. I plan to publish it by the end of the year.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Sharing that chat with Serena was another remarkable feature.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>Generative AI is not going to build your engineering team for you</title>
      <link>https://nicolaiarocci.com/generative-ai-is-not-going-to-build-your-engineering-team-for-you/</link>
      <pubDate>Fri, 14 Jun 2024 16:08:08 +0200</pubDate>
      <guid>https://nicolaiarocci.com/generative-ai-is-not-going-to-build-your-engineering-team-for-you/</guid>
      <description>&lt;p&gt;Charity Majors&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; has a good, long-form article on the Stack Overflow &lt;a href=&#34;https://stackoverflow.blog/2024/06/10/generative-ai-is-not-going-to-build-your-engineering-team-for-you/&#34;&gt;blog&lt;/a&gt;. The title is misleading as, while AI&amp;rsquo;s impact on software engineering and its hiring process (spoiler: you&amp;rsquo;ll still want to hire junior engineers) is at the heart of the article, there&amp;rsquo;s so much more in it. It gets exciting in the second part, where she dispenses much from-the-trenches advice on team management and building.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hiring engineers is about composing teams. The smallest unit of software ownership is not the individual, it’s the team.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Charity Majors<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> has a good, long-form article on the Stack Overflow <a href="https://stackoverflow.blog/2024/06/10/generative-ai-is-not-going-to-build-your-engineering-team-for-you/">blog</a>. The title is misleading as, while AI&rsquo;s impact on software engineering and its hiring process (spoiler: you&rsquo;ll still want to hire junior engineers) is at the heart of the article, there&rsquo;s so much more in it. It gets exciting in the second part, where she dispenses much from-the-trenches advice on team management and building.</p>
<blockquote>
<p>Hiring engineers is about composing teams. The smallest unit of software ownership is not the individual, it’s the team.</p></blockquote>
<blockquote>
<p>Have you ever been on a team packed exclusively with staff or principal engineers? It is not fun. That is not a high-functioning team. There is only so much high-level architecture and planning work to go around, there are only so many big decisions that need to be made. These engineers spend most of their time doing work that feels boring and repetitive, so they tend to over-engineer solutions and/or cut corners—sometimes at the same time. They compete for the “fun” stuff and find reasons to pick technical fights with each other. They chronically under-document and under-invest in the work that makes systems simple and tractable.</p></blockquote>
<blockquote>
<p>The best teams are ones where no one is bored, because every single person is working on something that challenges them and pushes their boundaries. The only way you can get this is by having a range of skill levels on the team.</p></blockquote>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I met her once at MongoDB headquarters in 2012 or 2013. We were invited back when they were running their now-long-defunct MongoDB Masters program. She worked at Parse then. Anyway, I remember being impressed by her competence and delivery.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>LLMs don&#39;t remember everything you say</title>
      <link>https://nicolaiarocci.com/llms-dont-remember-everything-you-say/</link>
      <pubDate>Wed, 29 May 2024 17:05:53 +0200</pubDate>
      <guid>https://nicolaiarocci.com/llms-dont-remember-everything-you-say/</guid>
      <description>&lt;p&gt;Simon Willison has a new article explaining an important and often ununderstood
aspect of LLMs. There&amp;rsquo;s a remarkable difference between chatting with an LLM, as
we users do, and training it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Short version: ChatGPT and other similar tools do not directly learn from and
memorize everything that you say to them.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Every time you start a new chat conversation, you clear the slate. Each
conversation is an entirely new sequence, carried out entirely independently of
previous conversations from both yourself and other users. Understanding this is
key to working effectively with these models. Every time you hit “new chat” you
are effectively wiping the short-term memory of the model, starting again from
scratch. This has a number of important consequences.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Simon Willison has a new article explaining an important and often ununderstood
aspect of LLMs. There&rsquo;s a remarkable difference between chatting with an LLM, as
we users do, and training it.</p>
<blockquote>
<p>Short version: ChatGPT and other similar tools do not directly learn from and
memorize everything that you say to them.</p></blockquote>
<blockquote>
<p>Every time you start a new chat conversation, you clear the slate. Each
conversation is an entirely new sequence, carried out entirely independently of
previous conversations from both yourself and other users. Understanding this is
key to working effectively with these models. Every time you hit “new chat” you
are effectively wiping the short-term memory of the model, starting again from
scratch. This has a number of important consequences.</p></blockquote>
<p>More <a href="https://simonwillison.net/2024/May/29/training-not-chatting/">here</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>What Open AI just did</title>
      <link>https://nicolaiarocci.com/what-open-ai-just-did/</link>
      <pubDate>Tue, 14 May 2024 08:41:04 +0200</pubDate>
      <guid>https://nicolaiarocci.com/what-open-ai-just-did/</guid>
      <description>&lt;p&gt;Open AI just released ChatGPT 4o. The launch demo is available on &lt;a href=&#34;https://www.youtube.com/live/DQacCB9tDaw&#34;&gt;YouTube&lt;/a&gt;, and yes, it is impressive. They did not launch v5, though, and 4o is only incremental, not exponential, as v4 has been compared to its predecessor. It may mean we&amp;rsquo;re at the end of the &amp;ldquo;exponential growth&amp;rdquo; phase of LLM models.&lt;/p&gt;
&lt;p&gt;However, the most critical aspect of this release is not technical, as Ethan Mollick correctly pinpoints in his timely &lt;a href=&#34;https://www.oneusefulthing.org/p/what-openai-did&#34;&gt;What Open AI Did&lt;/a&gt; post:&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Open AI just released ChatGPT 4o. The launch demo is available on <a href="https://www.youtube.com/live/DQacCB9tDaw">YouTube</a>, and yes, it is impressive. They did not launch v5, though, and 4o is only incremental, not exponential, as v4 has been compared to its predecessor. It may mean we&rsquo;re at the end of the &ldquo;exponential growth&rdquo; phase of LLM models.</p>
<p>However, the most critical aspect of this release is not technical, as Ethan Mollick correctly pinpoints in his timely <a href="https://www.oneusefulthing.org/p/what-openai-did">What Open AI Did</a> post:</p>
<blockquote>
<p>Likely the biggest impact of GPT-4o is not technical, but a business decision: soon everyone, whether they are paying or not, will get access to GPT-4o1. I think this is a big deal. When I talk with groups and ask people to raise their hands if they use ChatGPT, almost every hand goes up. When I ask if they used GPT-4, only 5% of hands remain up, at most. GPT-4 is so, so much better than free ChatGPT-3.5, it is like having a PhD student work with you instead of a high school sophomore. But that $20 a month barrier kept many people from understanding how impressive AI can be, and for gaining any benefit from AI. That is no longer true.</p></blockquote>
<p>He then speculates how this change will impact significant areas such as education, work, and global entrepreneurship.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Quoting Moxie Marlinspike</title>
      <link>https://nicolaiarocci.com/quoting-moxie-marlinspike/</link>
      <pubDate>Sat, 27 Apr 2024 11:37:19 +0200</pubDate>
      <guid>https://nicolaiarocci.com/quoting-moxie-marlinspike/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s very fast to build something that&amp;rsquo;s 90% of a solution. The problem is that the last 10% of building something is usually the hard part which really matters, and with a black box at the center of the product, it feels much more difficult to me to nail that remaining 10%. Closing that gap with gen AI feels much more fickle to me than a normal engineering problem. It could be that I&amp;rsquo;m unfamiliar with it, but I also wonder if some classes of generative AI based products are just doomed to mediocrity as a result.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>It&rsquo;s very fast to build something that&rsquo;s 90% of a solution. The problem is that the last 10% of building something is usually the hard part which really matters, and with a black box at the center of the product, it feels much more difficult to me to nail that remaining 10%. Closing that gap with gen AI feels much more fickle to me than a normal engineering problem. It could be that I&rsquo;m unfamiliar with it, but I also wonder if some classes of generative AI based products are just doomed to mediocrity as a result.</p></blockquote>
<p>&ndash; <a href="https://twitter.com/moxie/status/1783932933717561486">Moxie Marlinspike</a></p>
]]></content:encoded>
    </item>
    <item>
      <title>AI isn&#39;t useless. But is it worth it?</title>
      <link>https://nicolaiarocci.com/ai-isnt-useless.-but-is-it-worth-it/</link>
      <pubDate>Thu, 18 Apr 2024 15:19:20 +0200</pubDate>
      <guid>https://nicolaiarocci.com/ai-isnt-useless.-but-is-it-worth-it/</guid>
      <description>&lt;p&gt;Molly White&amp;rsquo;s experience with LLMs corresponds more or less with my own, but she is much better at recounting, critiquing, and drawing conclusions than I am.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I find my feelings about AI are actually pretty similar to my feelings about blockchains: &lt;strong&gt;they do a poor job of much of what people try to do with them, they can&amp;rsquo;t do the things their creators claim they one day might, and many of the things they are well suited to do may not be altogether that beneficial&lt;/strong&gt;. And while I do think that AI tools are more broadly useful than blockchains, they also come with similarly monstrous costs.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Molly White&rsquo;s experience with LLMs corresponds more or less with my own, but she is much better at recounting, critiquing, and drawing conclusions than I am.</p>
<blockquote>
<p>I find my feelings about AI are actually pretty similar to my feelings about blockchains: <strong>they do a poor job of much of what people try to do with them, they can&rsquo;t do the things their creators claim they one day might, and many of the things they are well suited to do may not be altogether that beneficial</strong>. And while I do think that AI tools are more broadly useful than blockchains, they also come with similarly monstrous costs.</p></blockquote>
<p>Brilliant.</p>
<blockquote>
<p>But the reality is that you can&rsquo;t build a hundred-billion-dollar industry around a technology that&rsquo;s kind of useful, mostly in mundane ways, and that boasts perhaps small increases in productivity if and only if the people who use it fully understand its limitations. And you certainly can&rsquo;t justify the kind of exploitation, extraction, and environmental cost that the industry has been mostly getting away with, in part because people have believed their lofty promises of someday changing the world.</p></blockquote>
<p>Full article <a href="https://www.citationneeded.news/ai-isnt-useless/">here</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>ChatGPT is the perfect Linux assistant</title>
      <link>https://nicolaiarocci.com/chatgpt-is-the-perfect-linux-assistant/</link>
      <pubDate>Fri, 29 Mar 2024 18:01:58 +0100</pubDate>
      <guid>https://nicolaiarocci.com/chatgpt-is-the-perfect-linux-assistant/</guid>
      <description>&lt;p&gt;I spent the day doing remote maintenance on multiple Linux machines via ssh. The
revelation is that ChatGPT is the bomb for these tasks: What does that command
option do? I am trying to remember. What syntax is to install that peculiar and
rarely used package on Debian? I am getting this locale configuration error;
what was the fix again? All this stuff is answered much sooner than searching
online, no matter the search engine.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>I spent the day doing remote maintenance on multiple Linux machines via ssh. The
revelation is that ChatGPT is the bomb for these tasks: What does that command
option do? I am trying to remember. What syntax is to install that peculiar and
rarely used package on Debian? I am getting this locale configuration error;
what was the fix again? All this stuff is answered much sooner than searching
online, no matter the search engine.</p>
<p>The feeling is having a good, untiring Linux connoisseur (and of all the various
ancillary packages) sitting right next to you, always ready to lend a hand. I
also think, and I&rsquo;m probably wrong (but my experience seems to bear this out so
far), that because these are all simple questions about stuff well carved in
stone, hallucinations are unlikely to occur.</p>
<p>My assistant today was ChatGPT 3.5, which is very old by today&rsquo;s LLM standards.
It is also free to use, which makes it all even more impressive.</p>
]]></content:encoded>
    </item>
    <item>
      <title>AI generated videos just changed forever</title>
      <link>https://nicolaiarocci.com/ai-generated-videos-just-changed-forever/</link>
      <pubDate>Fri, 16 Feb 2024 18:16:15 +0100</pubDate>
      <guid>https://nicolaiarocci.com/ai-generated-videos-just-changed-forever/</guid>
      <description>&lt;p&gt;Yesterday&amp;rsquo;s OpenAI launch of Sora is, as is always the case with OpenAI, mind-boggling. Marquees Browniee&amp;rsquo;s comment is spot-on, so much so as he&amp;rsquo;s obviously involved in the video-making scene.&lt;/p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/NXpdyAWLDas?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;I don&amp;rsquo;t think content creators are at risk with Sora, not anytime soon, but, as Marquees repeatedly notes in the video above, just one year ago we thought AI-generated video was a joke.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Yesterday&rsquo;s OpenAI launch of Sora is, as is always the case with OpenAI, mind-boggling. Marquees Browniee&rsquo;s comment is spot-on, so much so as he&rsquo;s obviously involved in the video-making scene.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/NXpdyAWLDas?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<p>I don&rsquo;t think content creators are at risk with Sora, not anytime soon, but, as Marquees repeatedly notes in the video above, just one year ago we thought AI-generated video was a joke.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Ethan Mollick&#39;s first impressions on Gemini Advanced</title>
      <link>https://nicolaiarocci.com/ethan-mollicks-first-impressions-on-gemini-advanced/</link>
      <pubDate>Thu, 08 Feb 2024 17:40:23 +0100</pubDate>
      <guid>https://nicolaiarocci.com/ethan-mollicks-first-impressions-on-gemini-advanced/</guid>
      <description>&lt;p&gt;Ethan Mollick, one of my few &lt;a href=&#34;https://nicolaiarocci.com/some-hints-about-what-the-next-year-of-ai-looks-like/&#34;&gt;LLM/AI
sources&lt;/a&gt;, just dropped
his first impressions on Gemini Advanced, released today, but which he&amp;rsquo;s been
testing for a month in early access.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Let me start with the headline: Gemini Advanced is clearly a GPT-4 class
model. The statistics show this, but so does a month of our informal testing.
And this is a big deal because OpenAI’s GPT-4 (the paid version of
ChatGPT/Microsoft Copilot) has been the dominant AI for well over a year, and no
other model has come particularly close. Prior to Gemini, we only had one
advanced AI model to look at, and it is hard drawing conclusions with a dataset
of one. Now there are two, and we can learn a few things.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Ethan Mollick, one of my few <a href="/some-hints-about-what-the-next-year-of-ai-looks-like/">LLM/AI
sources</a>, just dropped
his first impressions on Gemini Advanced, released today, but which he&rsquo;s been
testing for a month in early access.</p>
<blockquote>
<p>Let me start with the headline: Gemini Advanced is clearly a GPT-4 class
model. The statistics show this, but so does a month of our informal testing.
And this is a big deal because OpenAI’s GPT-4 (the paid version of
ChatGPT/Microsoft Copilot) has been the dominant AI for well over a year, and no
other model has come particularly close. Prior to Gemini, we only had one
advanced AI model to look at, and it is hard drawing conclusions with a dataset
of one. Now there are two, and we can learn a few things.</p></blockquote>
<p>Things are getting hotter in the LLM space, and competition is always good.</p>
<p>Full article
<a href="https://www.oneusefulthing.org/p/google-gemini-advanced-tasting-notes">here</a>.</p>
]]></content:encoded>
    </item>
    <item>
      <title>YouTube video summaries via ChatGPT</title>
      <link>https://nicolaiarocci.com/youtube-video-summaries-via-chatgpt/</link>
      <pubDate>Tue, 06 Feb 2024 09:45:04 +0100</pubDate>
      <guid>https://nicolaiarocci.com/youtube-video-summaries-via-chatgpt/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://just-tell-me.deno.dev&#34;&gt;Just Tell Me&lt;/a&gt; cleverly leverages ChatGPT to
provide short, insightful summaries of YouTube videos.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Have you ever wasted some time watching a youtube video, that got you kind of
interested because of the click-baity topic, but in the end turned out to be
nothing more BUT click-bait? Or have you ever wanted to just quickly recall what
a video that you&amp;rsquo;ve watched some time ago was about? Just Tell Me has you
covered!&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p><a href="https://just-tell-me.deno.dev">Just Tell Me</a> cleverly leverages ChatGPT to
provide short, insightful summaries of YouTube videos.</p>
<blockquote>
<p>Have you ever wasted some time watching a youtube video, that got you kind of
interested because of the click-baity topic, but in the end turned out to be
nothing more BUT click-bait? Or have you ever wanted to just quickly recall what
a video that you&rsquo;ve watched some time ago was about? Just Tell Me has you
covered!</p></blockquote>
<p>You can run it from the website or
<a href="https://github.com/franekmagiera/just-tell-me">locally</a> on the command line,
with your OpenAPI key and the LLM model of choice. I have not looked at the
code, but I understand it leverages the video transcript to do its magic<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. I&rsquo;ve
been using it for a while, and it&rsquo;s been good.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>I&rsquo;ve now looked at the code and the actual ChatGPT prompt is <em>&ldquo;You will be provided with video captions. Summarize the video in one paragraph&rdquo;</em>
(<a href="https://github.com/franekmagiera/just-tell-me/blob/04be5af4de743ca99d4480a9576830416ec3415e/app/src/get-captions-summary.ts#L23">link</a>).&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>Linus Torvalds on the impact of LLMs and AI on programming</title>
      <link>https://nicolaiarocci.com/linus-torvalds-on-the-impact-of-llms-and-ai-on-programming/</link>
      <pubDate>Sun, 21 Jan 2024 12:27:26 +0100</pubDate>
      <guid>https://nicolaiarocci.com/linus-torvalds-on-the-impact-of-llms-and-ai-on-programming/</guid>
      <description>&lt;p&gt;I think I like &lt;a href=&#34;https://www.youtube.com/watch?v=VHHT6W-N0ak&#34;&gt;his take&lt;/a&gt; on the topic.&lt;/p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; allowfullscreen=&#34;allowfullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/VHHT6W-N0ak?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;</description>
      <content:encoded><![CDATA[<p>I think I like <a href="https://www.youtube.com/watch?v=VHHT6W-N0ak">his take</a> on the topic.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/VHHT6W-N0ak?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

]]></content:encoded>
    </item>
    <item>
      <title>Some hints about what the next year of AI looks like</title>
      <link>https://nicolaiarocci.com/some-hints-about-what-the-next-year-of-ai-looks-like/</link>
      <pubDate>Sun, 07 Jan 2024 10:57:43 +0100</pubDate>
      <guid>https://nicolaiarocci.com/some-hints-about-what-the-next-year-of-ai-looks-like/</guid>
      <description>&lt;p&gt;Professor Ethan Mollick&amp;rsquo;s &lt;a href=&#34;https://www.oneusefulthing.org/p/signs-and-portents&#34;&gt;Signs and
Portents&lt;/a&gt; analyzes what AI
has achieved, what the effects have been so far, and what we might expect in
2024.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To ground ourselves, we can start with two quotes that should inform any
estimates about the future. The first is Amara&amp;rsquo;s Law: &amp;ldquo;We tend to overestimate
the effect of a technology in the short run and underestimate the effect in the
long run.&amp;rdquo; Social change is slower than technological change. We should not
expect to see immediate global effects of AI in a major way, no matter how fast
its adoption (and it is remarkably fast), yet we certainly will see it sooner
than many people think.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Professor Ethan Mollick&rsquo;s <a href="https://www.oneusefulthing.org/p/signs-and-portents">Signs and
Portents</a> analyzes what AI
has achieved, what the effects have been so far, and what we might expect in
2024.</p>
<blockquote>
<p>To ground ourselves, we can start with two quotes that should inform any
estimates about the future. The first is Amara&rsquo;s Law: &ldquo;We tend to overestimate
the effect of a technology in the short run and underestimate the effect in the
long run.&rdquo; Social change is slower than technological change. We should not
expect to see immediate global effects of AI in a major way, no matter how fast
its adoption (and it is remarkably fast), yet we certainly will see it sooner
than many people think.</p></blockquote>
<p>It&rsquo;s an insightful read that pairs well with Simon Wilson&rsquo;s <a href="/stuff-we-figured-out-about-ai-in-2023/">2023
round-up</a>. Also, his 30-second fake
video of himself telling things he never told is impressive.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Stuff we figured out about AI in 2023</title>
      <link>https://nicolaiarocci.com/stuff-we-figured-out-about-ai-in-2023/</link>
      <pubDate>Mon, 01 Jan 2024 11:46:22 +0100</pubDate>
      <guid>https://nicolaiarocci.com/stuff-we-figured-out-about-ai-in-2023/</guid>
      <description>&lt;p&gt;Simon Wilson, who&amp;rsquo;s recently been my go-to person for all AI-related stuff, has
an excellent &lt;a href=&#34;https://simonwillison.net/2023/Dec/31/ai-in-2023/&#34;&gt;2023 AI
round-up&lt;/a&gt; on his website.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;2023 was the breakthrough year for Large Language Models (LLMs). I think it&amp;rsquo;s
OK to call these AI—they&amp;rsquo;re the latest and (currently) most &amp;ldquo;interesting
development in the academic field of Artificial Intelligence that dates back to
the 1950s. Here&amp;rsquo;s my attempt to round up the highlights in one place!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The links contained within the post are also valuable. You may know Simon&amp;rsquo;s
website if you are interested in LLMs and AI. If you don&amp;rsquo;t, I suggest you start
following him, preferably via his RSS feed like real hackers do.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Simon Wilson, who&rsquo;s recently been my go-to person for all AI-related stuff, has
an excellent <a href="https://simonwillison.net/2023/Dec/31/ai-in-2023/">2023 AI
round-up</a> on his website.</p>
<blockquote>
<p>2023 was the breakthrough year for Large Language Models (LLMs). I think it&rsquo;s
OK to call these AI—they&rsquo;re the latest and (currently) most &ldquo;interesting
development in the academic field of Artificial Intelligence that dates back to
the 1950s. Here&rsquo;s my attempt to round up the highlights in one place!</p></blockquote>
<p>The links contained within the post are also valuable. You may know Simon&rsquo;s
website if you are interested in LLMs and AI. If you don&rsquo;t, I suggest you start
following him, preferably via his RSS feed like real hackers do.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Quoting Andrej Karpathy</title>
      <link>https://nicolaiarocci.com/quoting-andrej-karpathy/</link>
      <pubDate>Sat, 09 Dec 2023 07:05:25 +0100</pubDate>
      <guid>https://nicolaiarocci.com/quoting-andrej-karpathy/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;I always struggle a bit with I&amp;rsquo;m asked about the &amp;ldquo;hallucination problem&amp;rdquo; in LLMs. Because, in some sense, hallucination is all LLMs do. They are dream machines.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;We direct their dreams with prompts. The prompts start the dream, and based on the LLM&amp;rsquo;s hazy recollection of its training documents, most of the time the result goes someplace useful.&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;It&amp;rsquo;s only when the dreams go into deemed factually incorrect territory that we label it a &amp;ldquo;hallucination&amp;rdquo;. It looks like a bug, but it&amp;rsquo;s just the LLM doing what it always does.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<blockquote>
<p>I always struggle a bit with I&rsquo;m asked about the &ldquo;hallucination problem&rdquo; in LLMs. Because, in some sense, hallucination is all LLMs do. They are dream machines.</p></blockquote>
<blockquote>
<p>We direct their dreams with prompts. The prompts start the dream, and based on the LLM&rsquo;s hazy recollection of its training documents, most of the time the result goes someplace useful.</p></blockquote>
<blockquote>
<p>It&rsquo;s only when the dreams go into deemed factually incorrect territory that we label it a &ldquo;hallucination&rdquo;. It looks like a bug, but it&rsquo;s just the LLM doing what it always does.</p></blockquote>
<p>&ndash; <a href="https://twitter.com/karpathy/status/1733299213503787018">Andrej Karpathy</a></p>
]]></content:encoded>
    </item>
    <item>
      <title>Intro to Large Language Models (video)</title>
      <link>https://nicolaiarocci.com/intro-to-large-language-models-video/</link>
      <pubDate>Fri, 24 Nov 2023 07:05:25 +0100</pubDate>
      <guid>https://nicolaiarocci.com/intro-to-large-language-models-video/</guid>
      <description>&lt;p&gt;Andrej Karpathy has a very well-done &lt;a href=&#34;https://youtu.be/zjkBMFhNj_g?si=5tJNFaDcK-FBWnWK&#34;&gt;Intro to Large Language Models&lt;/a&gt;
video on YouTube. As a founding member and research scientist at OpenAI and with a two-year hiatus working on Tesla
Autopilot, Karpathy is an authority in the field. He is also good at explaining hard things.&lt;/p&gt;
&lt;p&gt;As a Kahneman reader, I appreciated the &lt;em&gt;Thinking Fast and Slow&lt;/em&gt; analogy proposed at about half-length in the video:
&amp;ldquo;System 1&amp;rdquo; (fast automatic thinking, rapid decisions) is where we&amp;rsquo;re now; &amp;ldquo;System 2&amp;rdquo; (rational, slow thinking, complex
decisions) is LLMs next goal. Also, I suspect Karpathy&amp;rsquo;s intriguing idea of LLMs as the center of a new &amp;ldquo;operating
system style&amp;rdquo; is not too far off from what will emerge soon. The final segment on AI security and known attack vectors
(jailbreaking, prompt injection, data poisoning) is also super interesting.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>Andrej Karpathy has a very well-done <a href="https://youtu.be/zjkBMFhNj_g?si=5tJNFaDcK-FBWnWK">Intro to Large Language Models</a>
video on YouTube. As a founding member and research scientist at OpenAI and with a two-year hiatus working on Tesla
Autopilot, Karpathy is an authority in the field. He is also good at explaining hard things.</p>
<p>As a Kahneman reader, I appreciated the <em>Thinking Fast and Slow</em> analogy proposed at about half-length in the video:
&ldquo;System 1&rdquo; (fast automatic thinking, rapid decisions) is where we&rsquo;re now; &ldquo;System 2&rdquo; (rational, slow thinking, complex
decisions) is LLMs next goal. Also, I suspect Karpathy&rsquo;s intriguing idea of LLMs as the center of a new &ldquo;operating
system style&rdquo; is not too far off from what will emerge soon. The final segment on AI security and known attack vectors
(jailbreaking, prompt injection, data poisoning) is also super interesting.</p>
<p>On his website, Karpathy also has a promising <a href="https://karpathy.ai/zero-to-hero.html">zero-to-hero video series</a>, &ldquo;a
course on building neural networks from scratch, in code.&rdquo;</p>
]]></content:encoded>
    </item>
    <item>
      <title>AI-curated minimalist news</title>
      <link>https://nicolaiarocci.com/ai-curated-minimalist-news/</link>
      <pubDate>Wed, 03 May 2023 07:05:25 +0100</pubDate>
      <guid>https://nicolaiarocci.com/ai-curated-minimalist-news/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.newsminimalist.com&#34;&gt;Minimalist News&lt;/a&gt; is the first LLM project that excites me but in a nervous way. Quoting the About page:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We only publish significant news. To find them we use AI (ChatGPT-4) to read and analyze 1000 top news every day. For
each article it estimates magnitude, scale, potential and credibility. Then we combine these estimates to get the
final Significance score from 0 to 10. And now the best part: We&amp;rsquo;ll only send you the news scored 6.5 or higher.
Sometimes it&amp;rsquo;s 5 articles, sometimes 2, sometimes 8. And sometimes — none at all. But one thing is constant — you can
be sure that you haven&amp;rsquo;t missed anything important.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p><a href="https://www.newsminimalist.com">Minimalist News</a> is the first LLM project that excites me but in a nervous way. Quoting the About page:</p>
<blockquote>
<p>We only publish significant news. To find them we use AI (ChatGPT-4) to read and analyze 1000 top news every day. For
each article it estimates magnitude, scale, potential and credibility. Then we combine these estimates to get the
final Significance score from 0 to 10. And now the best part: We&rsquo;ll only send you the news scored 6.5 or higher.
Sometimes it&rsquo;s 5 articles, sometimes 2, sometimes 8. And sometimes — none at all. But one thing is constant — you can
be sure that you haven&rsquo;t missed anything important.</p></blockquote>
<p>The concept is brilliant and well executed, but I can&rsquo;t help but feel uncomfortable at the notion of an AI curating news
for me. Yet, this is the best use case for LLM/AI I&rsquo;ve seen until now.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
