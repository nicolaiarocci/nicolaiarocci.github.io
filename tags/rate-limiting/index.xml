<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rate-limiting on Nicola Iarocci</title>
    <link>https://nicolaiarocci.com/tags/rate-limiting/</link>
    <description>Recent content in rate-limiting on Nicola Iarocci</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Produced / Written / Maintained by [Nicola Iarocci](/) since 2010</copyright>
    <lastBuildDate>Fri, 23 Dec 2022 07:05:25 +0100</lastBuildDate>
    <atom:link href="https://nicolaiarocci.com/tags/rate-limiting/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>On implementing the ASP.NET Core 7 rate-limiting middleware</title>
      <link>https://nicolaiarocci.com/on-implementing-the-asp.net-core-7-rate-limiting-middleware/</link>
      <pubDate>Fri, 23 Dec 2022 07:05:25 +0100</pubDate>
      <guid>https://nicolaiarocci.com/on-implementing-the-asp.net-core-7-rate-limiting-middleware/</guid>
      <description>Today, my last self-assigned duty before the Christmas break was to migrate our in-house rate-limiting implementation (based on the AspNetCoreRateLimiting third-party package) to the new, shiny rate-limiting middleware introduced by ASP.NET Core 7. While the process was relatively straightforward, I stumbled upon a few quirks I want to annotate here.
Our use case is simple. We use what the ASP.NET Core 7 documentation defines as a &amp;ldquo;fixed window limiter.&amp;rdquo; It uses a specified time window to limit requests.</description>
      <content:encoded><![CDATA[<p>Today, my last self-assigned duty before the Christmas break was to migrate
our in-house rate-limiting implementation (based on the
<a href="https://github.com/stefanprodan/AspNetCoreRateLimit">AspNetCoreRateLimiting</a> third-party package) to the new, shiny
<a href="https://devblogs.microsoft.com/dotnet/announcing-rate-limiting-for-dotnet/">rate-limiting middleware</a> introduced by ASP.NET Core 7. While the process
was relatively straightforward, I stumbled upon a few quirks I want to annotate
here.</p>
<p>Our use case is simple. We use what the ASP.NET Core 7 documentation defines as
a &ldquo;fixed window limiter.&rdquo; It uses a specified time window to limit requests.
When the time window expires, a new time window starts, and the request limit
is reset. Consider the following code (for convenience, I&rsquo;m using an extension
method):</p>
<pre tabindex="0"><code>public static void ConfigureRateLimit(this IServiceCollection services)
{
    services.AddRateLimiter(x =&gt; 
        x.AddFixedWindowLimiter(
                policyName: &#34;fixed&#34;, options =&gt;
                {
                    options.PermitLimit 1;
                    options.Window = TimeSpan.FromSeconds(10);
                    options.QueueLimit 1;
                }));
}
</code></pre><p>It sets a window of 10 seconds. Within that window, a maximum of one request is
allowed. Exceeding requests will be queued and served at window reset. Notice
that we defined &ldquo;fixed&rdquo; as the policy name.</p>
<p>Once our policy is configured, we must instrument the app instance to use the
rate limiter, then we call <code>RequireRateLimiting</code> on our endpoints:</p>
<pre tabindex="0"><code>app.UseRouting();  // I&#39;m mentioning this line for good reason, see below
app.UseRateLimiter();
app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers()
    .RequireRateLimiting(&#34;fixed&#34;); });
</code></pre><p>Nothing else is needed, really, for such a simple scenario. We could be more
sophisticated. We could opt for more advanced options, like a &ldquo;sliding windows
limiter&rdquo; or a &ldquo;bucket token limiter&rdquo;; we could apply rate limiting only to
specific endpoints or controllers or mix and match these options. I chose to
ditch hard-coded settings and read them from the configuration file. My
<em>appsettings.json</em> contains the following (with different vaues):</p>
<pre tabindex="0"><code>  &#34;RateLimiter&#34;: {
    &#34;PermitLimit&#34;: 1
    &#34;Window&#34;: 10,
    &#34;QueueLimit&#34;: 1
  }
</code></pre><p>The <code>RateLimiter</code> class maps the json structure:</p>
<pre tabindex="0"><code>public class RateLimiter
{
    public int PermitLimit { get; set; }
    public int Window { get; set; }
    public int QueueLimit { get; set; }
}
</code></pre><p>The updated code looks like this:</p>
<pre tabindex="0"><code>public static void ConfigureRateLimit(this IServiceCollection services, 
    IConfiguration configuration)
{
    var rateLimiter = new RateLimiter();
    configuration.GetSection(&#34;RateLimiter&#34;).Bind(rateLimiter);
    
    services.AddRateLimiter(x =&gt; 
        x.AddFixedWindowLimiter(
                policyName: &#34;fixed&#34;, options =&gt;
                {
                    options.PermitLimit = rateLimiter.PermitLimit;
                    options.Window = TimeSpan.FromSeconds(rateLimiter.Window);
                    options.QueueLimit = rateLimiter.QueueLimit;
                }));
}
</code></pre><p>I wish I could say it all worked splendidly on the first try. The API was
running fine, but it was not rate-limited. It looked like the middleware was
not being invoked, or it somehow failed miserably and silently. After an
embarrassingly long time, I figured out the problem: <code>UseRateLimiter</code>
<em>must</em> be called after <code>UseRouting</code>.</p>
<p>Before:</p>
<pre tabindex="0"><code>app.UseRateLimiter();
app.UseRouting();
app.UseEndpoints(endpoints =&gt; { endpoints
    .MapControllers().RequireRateLimiting(&#34;fixed&#34;); });
</code></pre><p>After:</p>
<pre tabindex="0"><code>app.UseRouting();
app.UseRateLimiter();
app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers()
    .RequireRateLimiting(&#34;fixed&#34;); });
</code></pre><p>Simply switching two lines saved the day. I looked high and low but could not
find any reference to this requirement. If intended, it should be mentioned in
the documentation. If it is a bug, it should be fixed (and I should
probably open at ticket about it.)</p>
<p>Anyways, now the API is rate-limited via the new middleware. The first request
sent via Postman goes through. The second, rapid-fired one is queued and served
at window reset, as expected. A third request within the same window is bounced
back.</p>
<p>However:</p>
<ol>
<li>You get a <code>503 Service Unavailable</code> response. I&rsquo;m not in favor of 500
replies for this case. Five-hundreds should be reserved for server errors,
and that&rsquo;s not what we are dealing with here. My previous implementation
served a more appropriate <code>429 Too Many Requests</code>.</li>
<li>No <code>Retry-After</code> header is included with the response. I think it&rsquo;s
mandatory to instruct clients on what to do next.</li>
</ol>
<p>Luckily, the rate-limiting middleware allows for ample customization. On
defining our policy, we can attach a custom function to the <code>OnRejected</code> event.
The code below is updated to address both issues above:</p>
<pre tabindex="0"><code>public static class ServicesConfiguration
{
    public static void ConfigureRateLimit(this IServiceCollection services, 
        IConfiguration configuration) {

        var rateLimiter = new RateLimiter();
        configuration.GetSection(&#34;RateLimiter&#34;).Bind(rateLimiter);
        
        services.AddRateLimiter(x =&gt; 
            x.AddFixedWindowLimiter(
                    policyName: &#34;fixed&#34;, options =&gt; {
                        options.PermitLimit = rateLimiter.PermitLimit;
                        options.Window = TimeSpan.FromSeconds(rateLimiter.Window);
                        options.QueueLimit = rateLimiter.QueueLimit;
                    })

                // new code here:
                .OnRejected = (context, _) =&gt; {

                // inject Retry-After header (too much line wrapping, I know)
                if (context.Lease.TryGetMetadata(MetadataName.RetryAfter, 
                    out var retryAfter)) {
                    context.HttpContext.Response.Headers.RetryAfter =
                        ((int) retryAfter.TotalSeconds).ToString();
                }
                // return a different status code
                context.HttpContext.Response.StatusCode = 
                    StatusCodes.Status429TooManyRequests;
                return new();
            });
    }
</code></pre><p>And that&rsquo;s all there is to it. I dropped the AspNetCoreRateLimiting dependency.
That is one great piece of software, and I am grateful to its author Stefan
Prodan and his contributors. As mentioned in <a href="/my-top-7-new-features-in-.net-7/">My Top 7 New Features in .NET
7</a>, they recently released a package that allows using Redis as a
rate-limiting backend. I might adopt it in the future.</p>
<p>Complete documentation for ASP.NET Core 7 rate-limiting middleware is available
<a href="https://learn.microsoft.com/en-us/aspnet/core/performance/rate-limit?view=aspnetcore-7.0">here</a>.</p>
<p><em>Subscribe to the <a href="https://buttondown.email/nicolaiarocci">newsletter</a>, the <a href="https://nicolaiarocci.com/index.xml">RSS feed</a>, or <a href="https://fosstodon.org/@nicola">follow me on Mastodon</a></em></p>
]]></content:encoded>
    </item>
  </channel>
</rss>
